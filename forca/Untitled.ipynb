{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d746b03",
   "metadata": {},
   "source": [
    "# Stock Price Prediction (Research)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48da226",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fab243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c19680",
   "metadata": {},
   "source": [
    "## Loading in the stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb43d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape S&P 500 tickers from Wikipedia\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "data = pd.read_html(url)\n",
    "sp500_tickers = data[0]['Symbol'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce444eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current date\n",
    "end_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# start date\n",
    "start_date = '1990-01-01'\n",
    "\n",
    "sp500_data = {}\n",
    "\n",
    "# Loop through each ticker in the S&P 500 list\n",
    "for ticker in sp500_tickers:\n",
    "    # Download historical data for the ticker from Yahoo Finance\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    \n",
    "    # Store the data in a Pandas DataFrame with the ticker as the column name\n",
    "    sp500_data[ticker] = pd.DataFrame(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943f4770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first few rows of each DataFrame\n",
    "for ticker, data_frame in sp500_data.items():\n",
    "    print(f\"First few rows of {ticker}:\")\n",
    "    print(data_frame.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb2df4c",
   "metadata": {},
   "source": [
    "## Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c31af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each ticker in the S&P 500 list\n",
    "for ticker in sp500_tickers:\n",
    "    # Download historical data for the ticker from Yahoo Finance\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    \n",
    "    # Store the data in a Pandas DataFrame with the ticker as the column name\n",
    "    sp500_data[ticker] = pd.DataFrame(data)\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_values = sp500_data[ticker].isnull().sum()\n",
    "    \n",
    "    # missing values for each ticker\n",
    "    print(f\"Missing values for {ticker}:\")\n",
    "    print(missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63f819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sp500_data['AAPL']['Open'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5385bdc1",
   "metadata": {},
   "source": [
    "There was no timezone found for 'BKR' and 'BR', hency why we are going to remove the tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f1ebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#['BRK.B']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
    "#['BF.B']: Exception('%ticker%: No price data found, symbol may be delisted (1d 1990-01-01 -> 2024-02-11)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db53655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_to_drop = ['BRK', 'BF'] \n",
    "\n",
    "for symbol in tickers_to_drop:\n",
    "    sp500_data.pop(symbol, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d625d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print keys before removal\n",
    "print(\"Keys before removal:\", sp500_data.keys())\n",
    "\n",
    "# Remove tickers\n",
    "tickers_to_drop = ['BRK', 'BF','BRK.B','BF.B','IQV']\n",
    "for symbol in tickers_to_drop:\n",
    "    sp500_data.pop(symbol, None)\n",
    "\n",
    "# Print keys after removal\n",
    "print(\"Keys after removal:\", sp500_data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c425953",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_to_check = 'BRK.B' and 'BF.B' and 'IQV'\n",
    "print(ticker_to_check in sp500_data.keys()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36cfbc3",
   "metadata": {},
   "source": [
    "There are no missing values for any of the stock tickers. We can proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3480b77c",
   "metadata": {},
   "source": [
    "##Â Visualization of Stock Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29807a59",
   "metadata": {},
   "source": [
    "Before we apply the engineering on the features and apply the machine learning models, we are going to plot the stock tickers to see the general movement of the stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54ad955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each ticker in the S&P 500 list\n",
    "for ticker in sp500_tickers:\n",
    "    # closing prices for the current ticker\n",
    "    closing_prices = sp500_data[ticker]['Close']\n",
    "    \n",
    "    # Plot the closing prices\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(closing_prices, label=ticker)\n",
    "    plt.title(f\"Closing Prices for {ticker}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Closing Price\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a38bb1",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3efb01",
   "metadata": {},
   "source": [
    "First of all, we are going to predict the stock prices by just simply using the available features. This will serve as a baseline for the upcoming improvements that will be applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d451d42",
   "metadata": {},
   "source": [
    "In the following, a target variable column is created.By calculating the difference between the closing and opening prices of a stock, we aim to capture the daily price movement, which serves as the target variable for machine learning algorithms. Shifting the target values by one row ensures that each day's target corresponds to the price movement on the subsequent trading day, facilitating the training of predictive models to forecast future price changes based on historical data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b739ce",
   "metadata": {},
   "source": [
    "Furthermore, we are going to use the target column in order to define a new column 'Direction'. The direction column willindicate if the price is going to go up (+1) or down (-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d984f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ticker, df in sp500_data.items():\n",
    "    #sp500_data[ticker]['Target'] = sp500_data[ticker]['Adj Close'] - sp500_data[ticker]['Open']\n",
    "    #sp500_data[ticker]['Target'] = sp500_data[ticker]['Target'].shift(-1)\n",
    "    \n",
    "    # Add a new column to indicate the direction of price change\n",
    "    #sp500_data[ticker]['Direction'] = np.where(sp500_data[ticker]['Target'] > 0, 1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e537f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker, df in sp500_data.items():\n",
    "    sp500_data[ticker]['Tomorrow'] = sp500_data[ticker]['Adj Close'].shift(-1)\n",
    "    sp500_data[ticker]['Target'] = np.where(sp500_data[ticker]['Tomorrow'] > sp500_data[ticker]['Adj Close'], 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103b951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sp500_data['AAPL']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ece0c8",
   "metadata": {},
   "source": [
    "We will use this as a basis for predicting the price movement for the next day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b29c436",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d737eba",
   "metadata": {},
   "source": [
    "We are going to scale the data using MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d356777",
   "metadata": {},
   "source": [
    "The last row of the target column which should represent the stock movement that needs to be predicted is nan. We are going to remove that row from each ticker and apply the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f038e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply scaling to each ticker\n",
    "for ticker, df in sp500_data.items():\n",
    "    # Remove rows with NaN values in the 'Tomorrow' column\n",
    "    df.dropna(subset=['Tomorrow'], inplace=True)\n",
    "    \n",
    "    # Check if there are still rows in the DataFrame\n",
    "    if not df.empty:\n",
    "        # Apply scaling to numeric columns\n",
    "        numeric_cols = df.select_dtypes(include='number').columns.drop(['Target', 'Tomorrow'])\n",
    "        df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values in each column\n",
    "nan_counts = df.isna().sum()\n",
    "\n",
    "# Print the number of NaN values in each column\n",
    "print(\"Number of NaN values in each column:\")\n",
    "print(nan_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c752997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each ticker and its corresponding DataFrame\n",
    "for ticker, df in sp500_data.items():\n",
    "    # Drop the last row\n",
    "    sp500_data[ticker] = df.drop(df.tail(1).index, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc96f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sp500_data['AAPL']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3770263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each ticker and its corresponding DataFrame\n",
    "for ticker, df in sp500_data.items():\n",
    "    # Separate features and target variables\n",
    "    X = df.drop(columns=['Target'])\n",
    "    y = df['Target']\n",
    "# Check for NaN values in y\n",
    "    if y.isna().any():\n",
    "        print(f\"NaN values found in the target variable for ticker {ticker}.\")\n",
    "    else:\n",
    "        print(f\"No NaN values found in the target variable for ticker {ticker}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f94ff1",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de83d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Dictionary to store the models and evaluation results\n",
    "models = {}\n",
    "\n",
    "# Iterate over each ticker and its corresponding DataFrame\n",
    "for ticker, df in sp500_data.items():\n",
    "    # Separate features \n",
    "    X = df.drop(columns=['Target','Tomorrow']) \n",
    "    y = df['Target']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize Logistic Regression model\n",
    "    model = LogisticRegression()\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model on the testing data\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Store the model and evaluation results\n",
    "    models[ticker] = {'model': model, 'accuracy': accuracy}\n",
    "\n",
    "# Access individual model and evaluation results\n",
    "for ticker, info in models.items():\n",
    "    print(f\"Ticker: {ticker}, Accuracy: {info['accuracy']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bd8b92",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f0c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "models = {}\n",
    "\n",
    "# Iterate over each ticker and its corresponding DataFrame\n",
    "for ticker, df in sp500_data.items():\n",
    "    \n",
    "    X = df.drop(columns=['Target','Tomorrow'])\n",
    "    y = df['Target']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize Random Forest Classifier model\n",
    "    model = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model on the testing data\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Store the model and evaluation results\n",
    "    models[ticker] = {'model': model, 'accuracy': accuracy}\n",
    "\n",
    "# Access individual model and evaluation results\n",
    "for ticker, info in models.items():\n",
    "    print(f\"Ticker: {ticker}, Accuracy: {info['accuracy']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e10322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store accuracy scores\n",
    "accuracy_scores = []\n",
    "\n",
    "# Iterate over each ticker and its corresponding accuracy\n",
    "for ticker, info in models.items():\n",
    "    accuracy_scores.append(info['accuracy'])\n",
    "\n",
    "# Calculate the average accuracy\n",
    "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "\n",
    "print(f\"Average Accuracy: {average_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304c9b29",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f604300",
   "metadata": {},
   "source": [
    "Next, we are going to apply LSTM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785bb3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Data Preparation\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert data to sequences\n",
    "def create_sequences(data, sequence_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:i+sequence_length])\n",
    "        y.append(data[i+sequence_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "sequence_length = 60  # Define the length of input sequences\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, sequence_length)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_scaled, sequence_length)\n",
    "\n",
    "# Model Architecture\n",
    "model = Sequential([\n",
    "    LSTM(units=50, return_sequences=True, input_shape=(sequence_length, X_train_seq.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(units=50, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(units=50),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=1)  # Output layer\n",
    "])\n",
    "\n",
    "# Model Compilation\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train_seq, y_train_seq, epochs=100, batch_size=32)\n",
    "\n",
    "# Model Evaluation\n",
    "loss = model.evaluate(X_test_seq, y_test_seq)\n",
    "\n",
    "# Prediction\n",
    "predictions = model.predict(X_test_seq)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
